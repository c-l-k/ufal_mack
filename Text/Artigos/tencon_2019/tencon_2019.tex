\documentclass[conference]{IEEEtran}
%\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}                        % AAB inserido
\usepackage[utf8]{inputenc}                  % AAB inserido
\usepackage{rotating}                        % AAB inserido
%\usepackage{subfigure}                       % AAB inserido
%\usepackage[export]{adjustbox}               % AAB inserido
\usepackage{bbm}

\ifCLASSOPTIONcompsoc                        % AAB inserido
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\else
\usepackage[caption=false,font=footnotesize]{subfig}
\fi
%\usepackage[round,sort,nonamebreak]{natbib}  % AAB inserido
%\usepackage[round,sort,nonamebreak]{natbib} % citação bibliográfica textual
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
%AAB
\DeclareMathOperator{\traco}{tr}
\graphicspath{{../../Dissertacao/figuras/}}
\begin{document}

\title{Fusion of Evidences for Edge Detection in PolSAR Images\\
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
%should not be used}
\thanks{Grantee Capes/PROSUP/Mackenzie.}
}
\author{\IEEEauthorblockN{Anderson A. de Borba}
\IEEEauthorblockA{\textit{Dept.\ Engenharia Elétrica e Computação} \\
\textit{UPM -- Universidade Presbiteriana Mackenzie}\\
IBMEC-SP\\
São Paulo, Brazil \\
anderson.borba@ibmec.edu.br}
\and
\IEEEauthorblockN{Maurício Marengoni}
\IEEEauthorblockA{\textit{Dept.\ Engenharia Elétrica e Computação} \\
\textit{UPM -- Universidade Presbiteriana Mackenzie}\\
São Paulo, Brazil \\
mauricio.marengoni@mackenzie.br}
\and
\IEEEauthorblockN{\hspace{6cm} Alejandro C. Frery}
\IEEEauthorblockA{\textit{\hspace{6cm}Laboratório de Computação Científica e Análise Numérica -- LACCAN} \\
\hspace{6cm}\textit{UFAL -- Universidade Federal de Alagoas}\\
\hspace{6cm} Maceió, Brazil \\
\hspace{6cm}acfrery@gmail.com}
}
\maketitle
\begin{abstract}
Polarimetric Synthetic Aperture Radar (PolSAR) has achieved an important position as a remote sensing imaging method. 
However, PolSAR images are contaminated with speckle, making its processing and analysis challenging tasks. 
The present study discusses an detection method based on the fusion of evidences obtained in the intensities channels of multilook PolSAR images.
The method consists of detecting transition points in the finest strip of data which spans two regions using the maximum likelihood.
This is applied to each of the three intensity channels (hh), (hv) and (vv). 
The fusion methods are simple average, stationary wavelet transform (SWT), principal component analysis (PCA) and ROC statistics.  
%%% Esperar o artigo ficar pronto e pontuar o que foi feito
The results indicate a good performance of the approach in detecting edges with possible paths for future research.
\end{abstract}

\begin{IEEEkeywords}
PolSAR, edge detection, maximum likelihood estimation, fusion
\end{IEEEkeywords}

\section{Introduction}\label{sec_01}

We present results on the detection and fusion of edge evidence applied to Polarimetric Synthetic Aperture Radar images (PolSAR). 
We employ models and algorithms as required for an appropriate treatment of their special statistical characteristics.

Among the available edge detection techniques for SAR imagery, it is worth mentioning those based on the gradient, Refs.~\cite{tlb, obw, flmc, fyf}, and on Markov chains, Ref.~\cite{bf}.
The former suffer from the effect of speckle, and the latter lead to computer intensive methods.
Ref.~\cite{gfn} presents a comparison between several edge detectors. 

Alternatively, techniques based on statistical modeling have been used in edge detection, Refs.~\cite{gmbf, fbgm, horrit, gfn} and, more recently, by means of \textit{Deep Learning}, Refs.~\cite{bac, ztmxzxf, tabmm, xstz}.

This work relies on ideas stemming from information fusion.
This approach has been followed by Refs.~\cite{sglmla,sg} in order to extract valuable knowledge from remotely sensed data.

This paper follows the statistical modeling approach, mainly the techniques described in Refs.~\cite{fbgm, nhfc} using the Wishart distribution.
The basis for the fusion of information is described in Refs.~\cite{mit, sg}. 

The objective of this work is shown the viability the procedure to detect edges in each channel of a PolSAR image and to perform the fusion of the edge evidence, with the task of understanding and of quantifying the importance of the information provided by each channel in order to provide a better detection.

The article is structured as follows: 
Section~\ref{sec_02} describes the statistical modeling for PolSAR data, 
its use is presented in Sections~\ref{sec_03}, \ref{sec_04}, ~\ref{sec_05}, and~\ref{sec_06}.
Section~\ref{sec_07} describes the fusion of edge evidence approaches with an emphasis on the ROC statistics-based method.
Numerical results are shown and analyzed in Section~\ref{sec_08} and, finally, Section~\ref{sec_09} concludes the paper with remarks, future research directions and the viability  to detect edges in each channel of a PolSAR image and to perform the fusion of the edge evidence is established.

\section{Statistical modeling for PolSAR data}\label{sec_02}

Fully polarimetric SAR systems transmit orthogonally polarized microwave pulses and measure orthogonal components of the received signal. 
For each pixel, we have a matrix of scattering coefficients, which are complex numbers and describe the transformation from the transmitted electromagnetic field to the received electromagnetic field.

The transformation can be represented as
\begin{equation*}
 \left[
\begin{array}{c}
	E_{\text{h}}^{\text{r}}   \\
	E_{\text{v}}^{\text{r}}    
\end{array}
\right]
 = \frac{e^{\hat{\imath} kr}}{r}\left[
\begin{array}{cc}
	S_\text{hh}   & S_\text{hv}   \\
	S_\text{vh}   & S_\text{vv}   
\end{array}
\right]
 \left[
\begin{array}{c}
	E_{\text{h}}^{\text{t}}   \\
	E_{\text{v}}^{\text{t}}    
\end{array}
\right],
\end{equation*}
where $k$ denotes the wave number, $\hat{\imath}$ is the complex unit, and $\text{r}$ is the distance between the radar and the target. 
The electromagnetic field with components $E_{\text{i}}^{\text{j}}$ has a subscribed index denoting horizontal ($\text{h}$) or vertical ($\text{v}$) polarization, while the superscript index indicates the received ($\text{r}$) or transmitted ($\text{t}$) wave. 
Defining $S_\text{ij}$ as the complex scattering coefficients, such that the indexes $\text{i}$ and $\text{j}$ are associated with the reception and transmission of waves, for example, the scattering coefficient $S_\text{hv}$ is associated with wave transmitted in the vertical direction ($\text{v}$) and received in the horizontal direction ($\text{h}$).

The complex scattering matrix $\mathbf{S}$ is defined by
\begin{equation}
\mathbf{S} = \left[
\begin{array}{cc}
	S_\text{hh}   & S_\text{hv}   \\
	S_\text{vv}   & S_\text{vv}   
\end{array}
\right],
\label{eq_01}
\end{equation}
and if the means of propagation of waves is reciprocal, then the reciprocity theorem, Ref.~\cite{lp}, allows us to state the scattering matrix as being Hermitian. 
In this way, the scattering matrix~(\ref{eq_01}) can be represented by the vector $\mathbf{s}=[S_\text{hh},S_\text{hv},S_{\text{vv}}]^T$.

Following Refs.~\cite{good, lee}, we will assume that the distribution of $\mathbf{s}$ is Gaussian circular complex multivariate with zero mean $N^{\mathbbm C}_3(0,\mathbf{\Sigma})$, and probability density function (pdf) given by:
\begin{equation}
    f_{\mathbf{s}}(\mathbf{s};\mathbf{\Sigma})=\frac{1}{\pi^3|\mathbf{\Sigma}|} \exp(-\mathbf{s}^H\mathbf{\Sigma}^{-1}\mathbf{s}),
    \label{eq_02}
\end{equation}
where $|\cdot|$ is the determinant, 
the superscript index $H$ denotes the conjugate complex number, 
and $\mathbf{\Sigma}$ is the covariance matrix of $\mathbf{s}$ such that $\mathbf{\Sigma}=E[\mathbf{ss}^H]$, where $E[\cdot]$ denotes the expected value. 

This statistical modeling has been confirmed for a variety of the polarimetric SAR data, and it contains all the necessary information to characterize the backscatter according to Refs.~\cite{sarabendi,mfp}
 
The statistical modelling described so far deals only with single-look modelling.
However, polarimetric images are usually subjected to a multi-look processing in order to improve the signal-to-noise ratio. 
For this purpose, Refs.~\cite{good, ade} show that estimated positive definite Hermitian matrices are obtained by computing the average of $L$ independent samples of the same scene, resulting in the estimated sample covariance matrix:
\begin{equation}
    \mathbf{Z}=\frac{1}{L}\sum_{\ell=1}^{L} {\mathbf{s}_\ell}{\mathbf{s}_\ell}^H,
    \label{eq_03}
\end{equation}
where $\mathbf{s}_\ell$, $\ell = 1, \dots, L$, are $L$ independent samples of complex vectors distributed as $\mathbf{s}$. 
The sample covariance matrix associated with $\mathbf{s}_\ell$ denotes the scattering for each of the $L$ looks.

\section{Multi-look Wishart density function}\label{sec_03}

Multi-looked data follow a Wishart distribution with probability density function (pdf) defined by:
\begin{equation}
    f_{\mathbf{Z}}(\mathbf{Z};\mathbf{\Sigma_{s}},L)=\frac{L^{mL}|\mathbf{Z}|^{L-m}}{|\mathbf{\Sigma_{s}}|^{L}\Gamma_m(L)} \exp(-L\traco(\mathbf{\Sigma_{s}}^{-1}\mathbf{Z})),
    \label{eq_04}
\end{equation} 
where, $\traco(\cdot)$ is the trace operator of an array, $\Gamma_m(L)$ is a multivariate Gamma function defined by
\begin{equation*}
	\Gamma_m(L)=\pi^{\frac{1}{2}m(m-1)} \prod_{i=0}^{m-1}\Gamma(L-i),
\end{equation*}
and $\Gamma(\cdot)$ is the Gamma function.
In our study we will consider $m=3$. 
We denote this situation $\mathbf{Z}\sim W(\mathbf{\Sigma_{s}}, L)$, which satisfies $E[\mathbf{Z}]=\mathbf{\Sigma_{s}}$. 
Since there is no ambiguity, we will use $\mathbf{\Sigma}$ instead of $\mathbf{\Sigma_{s}}$ to represent the covariance matrix associated with $\mathbf{S}$.

\section{Edge Detection}\label{sec_04}

Most of the usual techniques for edge detection, e.g., 
Sobel, Canny, Laplacian of Gaussian (LoG) and pyramidal LoG, assume additive Gaussian noise and, thus, are ineffective for PolSAR imagery.
The noise in these kind of images is multiplicative, making edge detection in SAR images a challenging task.

The main idea is based on Ref.~\cite{nhfc, gmbf} and show like to detect the transition point in a thin strip between two regions of the image. The transition point is considered as edge evidence. 

We propose the following procedure:
\begin{enumerate}
	\item identify the centroid of a region of interest (ROI) in an automatic, semi-automatic or manual manner;
	\item cast rays from the centroid to the outside of the area;
	\item collect data around the rays using the  Bresenham's midpoint line algorithm, ideally the size of a pixel;
	\item detect points in the data strips which provide evidence of changes in their statistical properties, i.e., a transition point that defines edge evidence;
	\item use the Generalized Simulated Anneling (GenSA) method, Ref.~\cite{xgsh}, to find maximum points in the functions of interest;
	\item fuse the evidence of detected edges in the $\text{hh}$, $\text{hv}$ and $\text{vv}$ channels.
\end{enumerate}
With this, we do not require fully polarized data, only the intensity channels.

\section{Maximum Likelihood Method}\label{sec_05}

Suppose $\mathbf{X}=(X_1,X_2,\dots,X_n)^T$ is a random vector distributed according to the probability density function (pdf) $f(\mathbf{x},\mathbf{\theta})$ with parameters $\mathbf{\theta}=(\theta_1,\dots,\theta_d)^T$ in the parameter space $\Theta$.
The likelihood function is
\begin{equation*}
    L(\theta;\mathbf{X}) = \prod_{i=1}^{n}f(x_i;\theta),
\end{equation*}
and the logarithmic likelihood function, which is also called the log-likelihood function is
\begin{equation}
	\ell(\theta;\mathbf{X})= \ln L(\theta;\mathbf{X}) = \sum_{i=1}^{n}\ln f(x_i;\theta).
	\label{eq_05}
\end{equation}

A maximum likelihood estimator is any point in $\Theta$ satisfying $\widehat{\theta}= \arg\max\limits_{\theta\in\Theta}L(\theta;\mathbf{x})$ or, equivalently, $\widehat{\theta}= \arg\max\limits_{\theta\in\Theta}\ell(\theta;\mathbf{x})$.

Consider now that the sample $\mathbf{Z}^T=(\mathbf{Z}_1,\mathbf{Z}_2,\dots,\mathbf{Z}_N)$ is split in two: $\mathbf{Z}_1,\dots,\mathbf{Z}_j$ and $\mathbf{Z}_{j+1},\dots,\mathbf{Z}_j$.
These parts may belong to two different Wishart distributions: those characterized by  $\mathbf{\Sigma_A}$, and $\mathbf{\Sigma_B}$, both with the same number of looks $L$.
Finding the edge consists in finding the point $j$ (or $j+1$) that separates them.

Finding the edge $j$ by maximum likelihood can be achieved by looking for the position $\widehat\jmath$ that maximizes the likelihood equation of the two samples:
%
\begin{equation}
	L(\widehat\jmath)=\prod_{k_1=1}^{\widehat\jmath}f_{\mathbf{Z}}(\mathbf{Z}_{k_1};\mathbf{\widehat\Sigma_{A}},L) \prod_{k_2=\widehat\jmath+1}^{N}f_{\mathbf{Z}}(\mathbf{Z}_{k_2};\mathbf{\widehat\Sigma_{B}},L),
	\label{eq_06}
\end{equation}
where $\mathbf{\widehat\Sigma_{A}}$ is the maximum likelihood estimator of $\mathbf{\Sigma_{A}}$ based on the sample $\mathbf{Z}_1,\dots,\mathbf{Z}_{\widehat\jmath}$, 
and $\mathbf{\widehat\Sigma_{B}}$ is the maximum likelihood estimator of $\mathbf{\Sigma_{B}}$ based on the sample $\mathbf{Z}_{\widehat\jmath+1},\dots,\mathbf{Z}_{N}$.
Analogously, one may optimize the log-likely function, i.e.,
\begin{equation}
\ell(\widehat\jmath) =
	\sum_{k_1=1}^{\widehat\jmath}\ln f_{\mathbf{Z}}(\mathbf{Z}_{k_1}; \mathbf{\widehat\Sigma_{A}},L) + \sum_{k_2=\widehat\jmath+1}^{N}\ln f_{\mathbf{Z}}(\mathbf{Z}_{k_2};     \mathbf{\widehat\Sigma_{B}},L).
	\label{eq_07}
\end{equation}
is maximum with respect to $1\leq j\leq N$.

The estimates for the covariance matrices can be found using the maximum likelihood estimator denoted by $\widehat{\Sigma}$, Ref.~\cite{good}: 
\begin{equation}
\widehat{\mathbf\Sigma_{I}}(\widehat\jmath) = \left\{
\begin{array}{lc}
	\widehat\jmath^{-1}\sum_{k=1}^{\widehat\jmath}\mathbf{Z}_{k}  & \mbox{if}\quad I=A,  \\
        (N-\widehat\jmath)^{-1}\sum_{k=\widehat\jmath+1}^{N}\mathbf{Z}_{k} & \mbox{if}\quad I=B.
\end{array}
\right.\label{eq_08}
\end{equation}

After algebraic manipulations on each term of the summation using~\eqref{eq_08}, we obtain
\begin{align}\nonumber
	\ell(\widehat\jmath)&=N\left[mL(\ln{L}-1)-\ln{\Gamma_m(L)}\right]\\\nonumber
	&- L\left[\widehat\jmath\ln{|\mathbf{\widehat{\Sigma}}_{A}(\widehat\jmath)|} +(N-\widehat\jmath)\ln{|\mathbf{\widehat{\Sigma}}_{B}(\widehat\jmath)|}\right] \\
	&+ (L-m)\sum_{k=1}^{N}\ln{|\mathbf{Z}_{k}|}.\label{eq_09}
\end{align}

The argument of the maximum $\widehat{\jmath}$ is the edge evidence that will be used in our fusion methods.

\section{Application in simulated images}\label{sec_06}

The methodology (MLE) for detecting edge evidence will be applied to a simulated image based on Refs.~\cite{nhfc,gamf}. 
The image has $400\times400$ pixels and is composed of two samples obeying the Wishart distribution; cf.\ Fig.~\ref{fig_Edges-Evidence}~\subref{fig_Edges-Evidence:a}.

For each pair of covariance matrices $\Sigma_{k_1}$, $\Sigma_{k_2}$ will be generated a PolSAR image $I_{k_1,k_2}$ as follows, in each write pixel of the simulated image the sample from  $W_G(\Sigma_{k_1}, L)$will be added,  and for each black pixel of the synthetic image the sample from $W_G(\Sigma_{k_2},L)$ will be added, and in the experiments presented they use the number of targets $L=4$

\begin{figure}[hbt]
     \subfloat[Pauli decomposition \label{fig_Edges-Evidence:a}]{%
       \fbox{\includegraphics[viewport= 80 50 490 460, clip=true, width=0.23\textwidth]{phanton_nhfc_dec_pauli}}      
     }
     \fbox{\subfloat[Marginal densities of the $\text{hh}$ channel\label{fig_Edges-Evidence:b}]{%
       \includegraphics[width=0.24\textwidth]{grafico_pdf_nhfc_2014_sigma_hh_artigos}}
     }
    \caption{Edges evidences}
     \label{fig_Edges-Evidence}
\end{figure}

Pauli's decomposition is based on vector representation in the linear combination of channels of intensity $(\mathbf{I_\text{hh}+I_{\text{vv}}}, \mathbf{I_\text{hh}+I_{\text{vv}}}, \mathbf{I_\text{hv}})$. The decomposition is shown in the figure Fig.~\ref{fig_Edges-Evidence}~\subref{fig_Edges-Evidence:a}. 

According to the probability density function (\ref{eq_04}) and defining the number of object $L=4$, we can generate the figure Fig.~\ref{fig_Edges-Evidence}~\subref{fig_Edges-Evidence:b}. The figure shows the density function for values of $\sigma_\text{hh}$ extracted from real data for forest and urban areas given respectively by $\sigma_\text{hh}=962892$ and $\sigma_\text{hh}= 360932$.  These constants are the same used in figure Fig.~\ref{fig_Edges-Evidence}~\subref{fig_Edges-Evidence:a}.
%
The simulated image was constructed with $400$ lines distributed in two vertically separated bands around the $200$ pixel, configuring the border; The image has dimension $400 \times 400$ where each line has two different sample sets generated with the parameters the $\Sigma$ parameters defined above.  

We arbitrarily fix the line that cuts the figure horizontally Fig.~\ref{fig_Edges-Evidence}~\subref{fig_Edges-Evidence:a} in two parts, that is, the $200$ number line. We will then have a line with two sample sets as a database to calculate the probability function $l(\widehat\jmath)$ according to equation (\ref{eq_09}) which should be applied to the channels $\mathbf{I_\text{hh}}$, $\mathbf{I_\text{vv}}$ and $\mathbf{I_{\text{vv}}}$ generating the figures Fig.~\ref{fig_evid_bordas}.  
    
\begin{figure}[hbt]
     \subfloat[Evidences in channel $\text{hh}$ \label{fig_evid_bordas:1a}]{%
       %\includegraphics[width=0.2\textwidth]{example-image-a}
       \includegraphics[width=0.2\textwidth]{grafico_l_nhfc_2014_sigmahh_artigos.pdf}       
     }
     \hfill
     \subfloat[Evidences in channel $\text{hv}$ \label{fig_evid_bordas:1b}]{%
       \includegraphics[width=0.2\textwidth]{grafico_l_nhfc_2014_sigmahv_artigos.pdf}
     }
     \\
     \centering
     \subfloat[Evidences in channel $\text{vv}$ \label{fig_evid_bordas:1c}]{%
       \includegraphics[width=0.2\textwidth]{grafico_l_nhfc_2014_sigmavv_artigos.pdf}
     }
     \caption{Edges evidences}
     \label{fig_evid_bordas}
   \end{figure}	

We can notice that the functions show a peak indicating the evidence of edges that should be captured, but the functions are not differentiable at many points, hindering the use of optimization methods that require the calculation of the derivative, with this performance of the methods are impaired. The problem has been solved using the Generalized Simulated Annealing (GenSA) method that we can find in the reference Ref.~\cite{xgsh} and works well in non-differentiable functions.
    
    The metric for the error used in this work follows the following procedure, we perform $400$ replications of the Wishart distribution with two sample sets, that is, we perform a process to generate $400$ simulated images. For each replication, the function $l(\widehat\jmath)$ is calculated in a fixed horizontal line arbitrary. The purpose is to find the argument of the maximum point by the method {\it Generalized Simulated annealing} (GenSA), thus finding the evidence of borders.
    
     By construction, we consider the vertical line $200$ as the real border in each replication, so the error for this replication is the absolute value of the difference between the real border point and the value estimated by the GenSA method. Thus, we calculate the error for each replication by
\begin{equation*}
\begin{array}{llll}
	E(r) &=& |200 - \hat{\jmath}(r)|, & 1\leq r \leq 400,  \\
\end{array}
\end{equation*}
where, $\hat{\jmath}(r)$ is the result of maximizing $l(\widehat\jmath)$ by the GenSA method on $r$ replication.

We will use relative frequencies to estimate the probability of having an error smaller than a number of pixels. Denoting for $H(k)$ the number of replications for which the error is less than $k$ pixels we calculate an estimate of this probability by $f(k)=\frac{H(k)}{400}$. In the tests performed in this section, we vary $k$ between $1$ and $10$. The algorithm is described in detail in Ref.~\cite{fbgm}.  
   \begin{figure}[hbt]
\centering
	\includegraphics[scale=0.4]{metricas_ihh_ivh_ivv_nhfc_artigos.pdf}%
			%\vspace{-1.0cm}
	\caption{Probability of detecting edges evidences.}
\label{probability_edge_detc}
\end{figure}
The Fig.~\ref{probability_edge_detc} shows the probabilities for edge detection when applying the GenSA method to channels $I_\text{hh}$, $I_\text{vv}$ and $I_{vvv}$ of the image. 
\section{Methods of fusion of border evidence}\label{sec_07}
\subsection{Simple average}
The simple average fusion method proposes the arithmetic mean of the edge evidence in each channel. The edge evidence fusion can be calculated by
\begin{equation}
	IF(x,y)=\frac{1}{nc}\sum_{i=1}^{nc}IE_i(x,y),
\end{equation}
where $nc$ is the number of channels to be used in the fusion. We can get more details on the Ref.~\cite{mit}.
\subsection{Stationary wavelet transform- SWT} 
This section is based on the Ref.~\cite{n_r}. The SWT fusion method can be described by the following steps:
\begin{itemize}
\item[-] calculate the SWT decomposition by getting $L_\text{HH}$, $L_\text{HL}$, $L_\text{LH}$ and $L_\text{LL}$ for each channel;
\item[-] in the decompositions $L_\text{HH}$, the arithmetic media of all channels is realized, pixel by pixel. And in the decompositions $L_\text{HL}$, $L_\text{LH}$ and $L_\text{LL}$, is found the maximum between each channel, pixel by pixel, leaving a new decomposition $\bar{L}_\text{HH}$, $\bar{L}_\text{HL}$, $\bar{L}_\text{LH}$ and $\bar{L}_\text{LL}$;
\item[-] performing the reverse transformation of SWT. We get the image by fusing the edge evidence $IF(x,y)$.  
\end{itemize}

\subsection{Principal component analysis - (PCA) }
This section is based on Refs.~\cite{n_r} and~\cite{mit}, where the PCA-based fusion method can be described by the following steps:
\begin{itemize}
\item[-] organize the data in such a way that each image has a column vector, forming a $Y$ matrix of dimension $l\times nc$, where $l=m\cdot n$, represents the multiplication of $m$ lines and $n$ columns of the matrices to be used in the fusion;
\item[-] calculate the average of the elements of these columns, generating a vector dimension of $1\times nc$;
\item[-] subtract the average of each column from the $Y$ matrix. Resulting in a $X$ matrix of the same dimension of $Y$; 
\item[-] find the $C$ covariance matrix from $X$, calculating $C=XX^T$;
\item[-] calculate the eigenvalues $\Lambda$ and the eigenvectors $D$, and sort the eigenvalues and eigenvectors in descending order. The matrices generated by the eigenvalues, on the main diagonal, and the eigenvectors placed in column, have dimensions $nc\times nc$;
\item[-] compute the components $P_i=\frac{V_i}{\sum_{i=1}^l V_i}$ with $i=1,\dots,nc$;
\item[-] we fuse $IF(x,y)=\sum_{i=1}^{nc}P_iIE_i(x,y)$. Remembering that the $\sum_{i=1}^{nc}P_i=1$.
\end{itemize}

\subsection{ROC statistics}
The ROC statistical method was proposed and described in detail in the Refs.~\cite{gs} and~\cite{fawcett}. The method describes a statistical model to obtain information automatically, from several images, or in several channels. The method can be described in the following procedures:
\begin{itemize}
\item[-] obtain the evidence of edges in the channels, applying the method described in this article. Store this edge evidence in $E_i$ matrices, with $i=1,\cdots,nc$ in a binary way;
\item[-] define a $V$ edge frequency matrix. The $V$ matrix is generated by adding the evidence of $E_i$ borders;
\item[-] use thresholds ranging from $t=1,\dots,nc$ generating $M_t$ matrices;
\item[-] compare each $M_t$, fixed with all $E_i$, find the confusion matrix to generate the ROC curve. The point of the ROC curve that approaches (in the sense of the Euclidean distance) the diagnostic line, we will have its threshold considered optimal;
\item[-] the $M_t$ matrix, which corresponds to the threshold closest to the diagnostic line, is the fusion of edge evidence.
\end{itemize}

\section{Numerical results}\label{sec_08}
The PolSAR image, with 4 looks of the Flevoland region in the Netherlands, was used for the numerical tests. The figure~(\ref{flevoland_radial_4look}) shows the region of interest, where it was built the radial lines for edge detection.

 Edge detection and subsequent evidence fusion were performed in this region of interest, in order to understand the weighting of each channel in the image formation.

In this study, edge detection was performed in the intensity channels $(hh)$, $(hv)$ and $(vv)$, and subsequently, used for information fusion. 
\begin{figure}[hbt]
\centering
	\includegraphics[scale=0.3]{flevoland_radial_4_look.pdf}
			\vspace{-1.0cm}
	\caption{Region of interest (ROI) in the image of Flavoland.}
\label{flevoland_radial_4look}
\end{figure}
The figures~\ref{evidencias_hh_hv_vv}~\subref{evidencias_hh_hv_vv:a},~\subref{evidencias_hh_hv_vv:b} and~\subref{evidencias_hh_hv_vv:c} show, respectively, the edge evidence detection algorithms, applied to $\text{(hh)}$, $\text{(hv)}$ and $\text{(vv)}$ channels. 

The algorithm to detect evidence of edges worked well in the channels $\text{(hh)}$ and $\text{(hv)}$, achieving better accuracy in relation to the channel $\text{(vv)}$.  

In the canal $\text{(vv)}$, edges that are not part of the homogeneous region of interest were detected, but are part of other edges of the image, researching the reason for this fact, we analysed the function $l(\widehat\jmath)$ and found that the function presents two peaks, representing possible evidence of edges, in which the largest was correctly detected. 
   \begin{figure}[!ht]
     \subfloat[Evidences in channel $(hh)$ \label{evidencias_hh_hv_vv:a}]{%
       \includegraphics[width=0.2\textwidth]{flevoland_hh_evid_crop_teste.pdf}       
     }
     \hfill
     \subfloat[Evidences in channel $(hv)$ \label{evidencias_hh_hv_vv:b}]{%
       \includegraphics[width=0.2\textwidth]{flevoland_hv_evid_crop_teste.pdf}
     }
     \\
     \centering
     \subfloat[Evidences in channel $(vv)$ \label{evidencias_hh_hv_vv:c}]{%
       \includegraphics[width=0.2\textwidth]{flevoland_vv_evid_crop_teste.pdf}
     }
     \caption{Edges evidences}
     \label{evidencias_hh_hv_vv}
   \end{figure}

The figures~\ref{fusion_met}~\subref{fusion_met:a},~\subref{fusion_met:b},~\subref{fusion_met:c} and~\subref{fusion_met:d} show, respectively, the fusion of evidence for the methods described in this article. In order, we list the method that shows the average of edges evidences, the method that uses the Stationary wavelet transform (SWT), the method that uses the Principal component analysis (PCA), and finally, the method based on ROC statistics.

The methods shown in the figures~\ref{fusion_met}~\subref{fusion_met:a},~\subref{fusion_met:b},~\subref{fusion_met:c} and~\subref{fusion_met:d} use all the pixels detected in the different channels. Each method weighs the pixels in the different channels with their characteristics. The average weighs the pixels in an equal manner. The (SWT) finds the coefficients of the linear combination of its wavelet bases, and the (PCA) weights the auto-vectors of the covariance matrix.

The ROC statistics method does not use all pixels of the channels, because the method is based on thresholds discarding pixels. This was observed in the figure~\ref{fusion_met}~\subref{fusion_met:d}.

\begin{figure}[!ht]
     \subfloat[Averege fusion\label{fusion_met:a}]{%
       %\includegraphics[width=0.2\textwidth]{example-image-a}
       \includegraphics[width=0.2\textwidth]{flevoland_fusao_media_crop_teste.pdf}       
     }
     \hfill
     \subfloat[SWT fusion\label{fusion_met:b}]{%
       \includegraphics[width=0.2\textwidth]{flevoland_fusao_swt_crop_teste.pdf}
     }
     \\
     \subfloat[PCA fusion \label{fusion_met:c}]{%
       %\includegraphics[width=0.2\textwidth]{example-image-a}
       \includegraphics[width=0.2\textwidth]{flevoland_fusao_pca_crop_teste.pdf}       
     }
     \hfill
     \subfloat[ROC fusion\label{fusion_met:d}]{%
       \includegraphics[width=0.2\textwidth]{flevoland_fusao_roc_crop_teste.pdf}
     }
     \caption{Fusion methods}
     \label{fusion_met}
   \end{figure}

\section{Conclusion}\label{sec_09}
In this study, the statistical modelling approach was applied to real PolSAR data imaging. Aiming to understand the importance of information from each channel in the edge evidence fusions. The proposed algorithm was applied in intensity channels $(hh)$, $(hv)$ and $(vv)$, it was found the evidence of edges, using the maximum likelihood  method in each channel, obtaining good results. After analyzed the results obtained in the intensity channels, it was observed that the method for the edge detections worked better in the channels $(hh)$ and $(hv)$ than the channel $(vv)$, achieving a suitable accuracy.

Subsequently, the fusion of evidence of edges was performed with the methods of simple average, SWT, PCA and ROC statistics. The first three methods performed well as shown in the results. The ROC statistics method suppressed several edge points, a behaviour expected because it is a method that uses thresholds; however, when applied in a larger number of channels, its performance tends to improve. 

Based on these results, a possible way to improve them would be to increase the number of channels studied. This analysis open a path for future researches with application of different methods for edge evidence fusing.
\bibliographystyle{IEEEtran}
\bibliography{bibliografia}
\end{document}
