\documentclass[journal]{IEEEtran}
%DIF LATEXDIFF DIFFERENCE FILE
%DIF DEL FusionEvidencesPolSAR-R0.tex   Sun May  3 16:47:48 2020
%DIF ADD FusionEvidencesPolSAR-R1.tex   Sat Jul 11 14:53:37 2020

\usepackage{cite}
%DIF 4a4
\usepackage{times} %DIF > 
%DIF -------
\usepackage{amsmath,amssymb,amsfonts}
%DIF 5c6
%DIF < \usepackage{algorithmic}
%DIF -------
\usepackage[boxed]{algorithm2e} %DIF > 
%DIF -------

\usepackage{graphicx}
\graphicspath{{../../Dissertacao/figuras/}}

\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}                        % AAB inserido
\usepackage[utf8]{inputenc}                  % AAB inserido
\usepackage{rotating}                        % AAB inserido
\usepackage{mathtools}                       % AAB inserido

\usepackage{bm,bbm}
\usepackage[binary-units]{siunitx}

\usepackage[caption=false,font=footnotesize]{subfig}
\DeclareMathOperator{\traco}{tr}
%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF UNDERLINE PREAMBLE %DIF PREAMBLE
\RequirePackage[normalem]{ulem} %DIF PREAMBLE
\RequirePackage{color}\definecolor{RED}{rgb}{1,0,0}\definecolor{BLUE}{rgb}{0,0,1} %DIF PREAMBLE
\providecommand{\DIFadd}[1]{{\protect\color{blue}\uwave{#1}}} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{{\protect\color{red}\sout{#1}}}                      %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
\providecommand{\DIFmodbegin}{} %DIF PREAMBLE
\providecommand{\DIFmodend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
\newcommand{\DIFscaledelfig}{0.5}
%DIF HIGHLIGHTGRAPHICS PREAMBLE %DIF PREAMBLE
\RequirePackage{settobox} %DIF PREAMBLE
\RequirePackage{letltxmacro} %DIF PREAMBLE
\newsavebox{\DIFdelgraphicsbox} %DIF PREAMBLE
\newlength{\DIFdelgraphicswidth} %DIF PREAMBLE
\newlength{\DIFdelgraphicsheight} %DIF PREAMBLE
% store original definition of \includegraphics %DIF PREAMBLE
\LetLtxMacro{\DIFOincludegraphics}{\includegraphics} %DIF PREAMBLE
\newcommand{\DIFaddincludegraphics}[2][]{{\color{blue}\fbox{\DIFOincludegraphics[#1]{#2}}}} %DIF PREAMBLE
\newcommand{\DIFdelincludegraphics}[2][]{% %DIF PREAMBLE
\sbox{\DIFdelgraphicsbox}{\DIFOincludegraphics[#1]{#2}}% %DIF PREAMBLE
\settoboxwidth{\DIFdelgraphicswidth}{\DIFdelgraphicsbox} %DIF PREAMBLE
\settoboxtotalheight{\DIFdelgraphicsheight}{\DIFdelgraphicsbox} %DIF PREAMBLE
\scalebox{\DIFscaledelfig}{% %DIF PREAMBLE
\parbox[b]{\DIFdelgraphicswidth}{\usebox{\DIFdelgraphicsbox}\\[-\baselineskip] \rule{\DIFdelgraphicswidth}{0em}}\llap{\resizebox{\DIFdelgraphicswidth}{\DIFdelgraphicsheight}{% %DIF PREAMBLE
\setlength{\unitlength}{\DIFdelgraphicswidth}% %DIF PREAMBLE
\begin{picture}(1,1)% %DIF PREAMBLE
\thicklines\linethickness{2pt} %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\framebox(1,1){}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\line( 1,1){1}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,1){\line(1,-1){1}}}% %DIF PREAMBLE
\end{picture}% %DIF PREAMBLE
}\hspace*{3pt}}} %DIF PREAMBLE
} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbegin}{\DIFaddbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddend}{\DIFaddend} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbegin}{\DIFdelbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelend}{\DIFdelend} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbegin}{\DIFOaddbegin \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbegin}{\DIFOdelbegin \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbeginFL}{\DIFaddbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddendFL}{\DIFaddendFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbeginFL}{\DIFdelbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelendFL}{\DIFdelendFL} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbeginFL}{\DIFOaddbeginFL \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbeginFL}{\DIFOdelbeginFL \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
%DIF LISTINGS PREAMBLE %DIF PREAMBLE
\RequirePackage{listings} %DIF PREAMBLE
\RequirePackage{color} %DIF PREAMBLE
\lstdefinelanguage{DIFcode}{ %DIF PREAMBLE
%DIF DIFCODE_UNDERLINE %DIF PREAMBLE
  moredelim=[il][\color{red}\sout]{\%DIF\ <\ }, %DIF PREAMBLE
  moredelim=[il][\color{blue}\uwave]{\%DIF\ >\ } %DIF PREAMBLE
} %DIF PREAMBLE
\lstdefinestyle{DIFverbatimstyle}{ %DIF PREAMBLE
	language=DIFcode, %DIF PREAMBLE
	basicstyle=\ttfamily, %DIF PREAMBLE
	columns=fullflexible, %DIF PREAMBLE
	keepspaces=true %DIF PREAMBLE
} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim}{\lstset{style=DIFverbatimstyle}}{} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim*}{\lstset{style=DIFverbatimstyle,showspaces=true}}{} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

\begin{document}
\title{Fusion of Evidences in Intensities Channels for Edge Detection in PolSAR Images}
\author{Anderson A.\ de Borba, Maurício Marengoni, and Alejandro C.\ Frery,~\IEEEmembership{Senior Member,~IEEE}%
\thanks{A.\ A.\ de Borba is with the Dept.\ Engenharia Elétrica e Computação, Universidade Presbiteriana Mackenzie (UPM), and with IBMEC-SP, São Paulo, Brazil. anderson.borba@ibmec.edu.br}
\thanks{M.\ Marengoni is with the Dept.\ Engenharia Elétrica e Computação,
UPM, São Paulo, Brazil. mauricio.marengoni@mackenzie.br}
\thanks{A.\ C.\ Frery is with the Laboratório de Computação Científica e Análise Numérica (LaCCAN), Universidade Federal de Alagoas (UFAL), Maceió, Brazil. acfrery@laccan.ufal.br}}

\maketitle

\begin{abstract}
\DIFdelbegin \DIFdel{Synthetic Polarimetric }\DIFdelend \DIFaddbegin \DIFadd{Polarimetric Synthetic }\DIFaddend Aperture Radar (PolSAR) sensors have reached an essential position in remote sensing. 
The images they provide have speckle noise, making their processing and analysis challenging tasks. 
\DIFdelbegin \DIFdel{The present study discusses }\DIFdelend \DIFaddbegin \DIFadd{We discuss }\DIFaddend an edge detection method based on the fusion of \DIFdelbegin \DIFdel{evidence }\DIFdelend \DIFaddbegin \DIFadd{evidences }\DIFaddend obtained in the intensity \DIFdelbegin \DIFdel{(hh), (hv), and (vv) channels }\DIFdelend \DIFaddbegin \DIFadd{channels (hh, hv, and vv) }\DIFaddend of PolSAR multi-look images. 
The method consists of detecting transition points in the thinnest possible range of data that covers two regions using maximum likelihood under the Wishart distribution. 
The fusion methods used are 
simple average, 
multi-resolution discrete (MR-DWT) and 
stationary (MR-SWT) wavelet transforms, 
principal component analysis (PCA), 
ROC statistics, 
and a multi-resolution method based on singular value decomposition (MR-SVD). 
A quantitative analysis suggests that MR-SWT provides the best results.
\end{abstract}

\begin{IEEEkeywords}
PolSAR, edge detection, maximum likelihood estimation, fusion methods. 
\end{IEEEkeywords}

\section{Introduction}\label{sec_01}
\IEEEPARstart{P}{olarimetric} synthetic aperture radar (PolSAR) has achieved an essential position \DIFdelbegin \DIFdel{as a remote sensingtechnology}\DIFdelend \DIFaddbegin \DIFadd{in remote sensing}\DIFaddend . 
The data such sensors provide require specifically tailored signal processing techniques.
Among such techniques, edge detection is one of the most important operations for extracting information.
Edges are at a higher level of abstraction than mere data and, as such, provide relevant insights about the scene.

Among the available edge detection techniques for SAR and PolSAR images, it is worth mentioning: \DIFdelbegin %DIFDELCMD < \begin{itemize}
%DIFDELCMD < \item %%%
\DIFdelend techniques based on denoising~\DIFdelbegin \DIFdel{\mbox{%DIFAUXCMD
\cite{sjx, lzly, wxbzw, law, cgaf}}\hspace{0pt}%DIFAUXCMD
;   
}%DIFDELCMD < \item %%%
\DIFdelend \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\cite{sjx, lzly, wxbzw, cgaf}}\hspace{0pt}%DIFAUXCMD
;   
}\DIFaddend Markov random fields~\cite{bf};	
\DIFdelbegin %DIFDELCMD < \item %%%
\DIFdelend the deep learning approach~\DIFdelbegin \DIFdel{\mbox{%DIFAUXCMD
\cite{bac, ztmxzxf} }\hspace{0pt}%DIFAUXCMD
}\DIFdelend \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\cite{ztmxzxf} }\hspace{0pt}%DIFAUXCMD
}\DIFaddend applied to segmentation and classification; and
\DIFdelbegin \DIFdel{,
}%DIFDELCMD < \item %%%
\DIFdelend statistical techniques~\cite{gmbf, fbgm, nhfc} applied in edge detection in PolSAR \DIFdelbegin \DIFdel{/ }\DIFdelend \DIFaddbegin \DIFadd{and }\DIFaddend SAR imagery.
\DIFdelbegin %DIFDELCMD < \end{itemize}
%DIFDELCMD < %%%
\DIFdelend 

This article follows the statistical modeling approach using the techniques described in~\cite{gmbf, fbgm, nhfc} to find edge evidences, followed by fusion processes~\cite{mit, bmf_2019}. 
\DIFdelbegin \DIFdel{Our approach does not attempt to reduce the speckle, but to extract information from its statistical properties.
}\DIFdelend %DIF > Our approach does not attempt to reduce the speckle, but to extract information from its statistical properties.

Instead of handling fully polarimetric data, we treat each intensity channel separately, obtain evidence of edges, and then produce a single estimator of the edge position.
With this, we quantify the contribution each channel provides to the solution of the problem.

\DIFdelbegin \DIFdel{We adopted the }\DIFdelend \DIFaddbegin \DIFadd{The }\DIFaddend Gambini Algorithm~\cite{gmbf_sc} \DIFdelbegin \DIFdel{, which }\DIFdelend \DIFaddbegin \DIFadd{is an attractive edge detection technique.
It is local, as it finds evidence of an edge over a thin strip of data; 
it works with any model, which makes it suitable for SAR data; 
and it has shown better performance than other approaches.
This algorithm }\DIFaddend consists in casting rays\DIFaddbegin \DIFadd{, }\DIFaddend and then finding the evidence of an edge in the ray by maximizing a value function.
\DIFdelbegin \DIFdel{The value function we use is the }\DIFdelend \DIFaddbegin \DIFadd{We use the total }\DIFaddend likelihood of two samples: one inside the edge, another outside the edge.
Without loss of generality, we assume the complex scaled Wishart distribution for the fully polarimetric observations\DIFdelbegin \DIFdel{~\mbox{%DIFAUXCMD
\cite{ade}}\hspace{0pt}%DIFAUXCMD
}\DIFdelend , from which Gamma laws stem for each intensity channel.
The value function depends on the estimates that index such Gamma laws\DIFdelbegin \DIFdel{.
We }\DIFdelend \DIFaddbegin \DIFadd{; and
we }\DIFaddend estimate them by maximum likelihood\DIFdelbegin \DIFdel{with the BFGS optimization method implemented in the }\texttt{\DIFdel{maxLik}} %DIFAUXCMD
\DIFdel{package~\mbox{%DIFAUXCMD
\cite{ht}}\hspace{0pt}%DIFAUXCMD
}\DIFdelend .

The \DIFdelbegin \DIFdel{value function is the total likelihood .
It }\DIFdelend \DIFaddbegin \DIFadd{total likelihood function }\DIFaddend is non-differentiable at most points\DIFdelbegin \DIFdel{in the domain. 
It is known that }\DIFdelend \DIFaddbegin \DIFadd{, and }\DIFaddend classical methods have difficulties in finding \DIFdelbegin \DIFdel{the maximumof a non-differentiable functions}\DIFdelend \DIFaddbegin \DIFadd{its maximum}\DIFaddend . 
We used the Generalized Simulated Annealing (GenSA)~\cite{xgsh} method to solve this problem. 

We discuss \DIFaddbegin \DIFadd{and compare }\DIFaddend six fusion methods:
\DIFdelbegin %DIFDELCMD < \begin{itemize}
%DIFDELCMD < \item %%%
\DIFdelend Simple average~\cite{mit}, 
\DIFdelbegin %DIFDELCMD < \item %%%
\DIFdelend Multi-Resolution Discrete Wavelet, MR-DWT~\cite{n_r},
\DIFdelbegin %DIFDELCMD < \item %%%
\DIFdelend Principal Component Analysis, PCA~\cite{n_r,mit},
\DIFdelbegin %DIFDELCMD < \item %%%
\DIFdelend ROC statistics~\DIFdelbegin \DIFdel{\mbox{%DIFAUXCMD
\cite{gs,fawcett}}\hspace{0pt}%DIFAUXCMD
,
}%DIFDELCMD < \item %%%
\DIFdelend \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\cite{gs}}\hspace{0pt}%DIFAUXCMD
,
}\DIFaddend Multi-Resolution Stationary Wavelet Transform, MR-SWT~\cite{n_r, jjly}, and 
\DIFdelbegin %DIFDELCMD < \item %%%
\DIFdelend Multi-Resolution Singular Value Decomposition, MR-SVD~\cite{naidu}.
\DIFdelbegin %DIFDELCMD < \end{itemize}
%DIFDELCMD < %%%
\DIFdelend 

%It aims to show the feasibility of a procedure for edge detection in PolSAR images using the fusion methods.

%The objective is to understand and quantify the importance of the information provided by each channel to improve the edge detection process.

The article is structured as follows.
Section~\ref{sec_02} describes \DIFdelbegin \DIFdel{statistical modeling}\DIFdelend \DIFaddbegin \DIFadd{the models}\DIFaddend .
Section~\ref{sec_03} describes \DIFdelbegin \DIFdel{edge detection for PolSAR data}\DIFdelend \DIFaddbegin \DIFadd{the edge detection}\DIFaddend .
Section~\ref{sec_04} describes the \DIFdelbegin \DIFdel{approach to edge evidence fusing }\DIFdelend \DIFaddbegin \DIFadd{approaches for fusing edge evidences}\DIFaddend .
Section~\ref{sec_05} presents \DIFdelbegin \DIFdel{numerical results.
Finally, }\DIFdelend \DIFaddbegin \DIFadd{the results.
In }\DIFaddend Section~\ref{sec_06} \DIFdelbegin \DIFdel{concludes the work with observations, future directions of research , and the feasibility of detecting edges in each channel of PolSAR images}\DIFdelend \DIFaddbegin \DIFadd{we discuss the results, and outline future research directions}\DIFaddend .

\section{Statistical modeling for PolSAR data}\label{sec_02}

Multi-looked fully polarimetric data follow the Wishart distribution with PDF defined by:
\begin{equation}
    f_{\mathbf{Z}}(\DIFdelbegin \DIFdel{\mathbf{Z}}\DIFdelend \DIFaddbegin \DIFadd{\mathbf{z}}\DIFaddend ;\mathbf{\Sigma},L)=\DIFdelbegin \DIFdel{\frac{L^{mL}|\mathbf{Z}|^{L-m}}{|\mathbf{\Sigma}|^{L}\Gamma_m(L)} }\DIFdelend \DIFaddbegin \DIFadd{\frac{L^{mL}|\mathbf{z}|^{L-m}}{|\mathbf{\Sigma}|^{L}\Gamma_m(L)} }\DIFaddend \exp(-L\traco(\mathbf{\Sigma}^{-1}\DIFdelbegin \DIFdel{\mathbf{Z}}\DIFdelend \DIFaddbegin \DIFadd{\mathbf{z}}\DIFaddend )),
    \label{eq:DistWishart}
\end{equation} 
where \DIFdelbegin \DIFdel{, }\DIFdelend \DIFaddbegin \DIFadd{$\mathbf z$ is a positive-definite Hermitian matrix, 
$L$ is the number of looks, }\DIFaddend $\traco(\cdot)$ is the trace operator of a matrix, $\Gamma_m(L)$ is the multivariate Gamma function defined by $
	\Gamma_m(L)=\pi^{\frac{1}{2}m(m-1)} \prod_{i=0}^{m-1}\Gamma(L-i)$,
and $\Gamma(\cdot)$ is the Gamma function.
We used three $m=3$ channels in this study. 
This situation is denoted by $\mathbf{Z}\sim W(\mathbf{\Sigma}, L)$, which satisfies $E[\mathbf{Z}]=\mathbf{\Sigma}$. 
This assumption usually holds \DIFdelbegin \DIFdel{on targets where the speckle is fully developed }\DIFdelend \DIFaddbegin \DIFadd{for fully developed speckle }\DIFaddend but, since we will estimate $L$ \DIFdelbegin \DIFdel{on each sample (}\DIFdelend \DIFaddbegin \DIFadd{locally }\DIFaddend instead of considering the same number of looks for the whole image\DIFdelbegin \DIFdel{)}\DIFdelend , we will in part take into account departures from such hypothesis.

\DIFdelbegin \DIFdel{Fully polarimetric data may be modeled by~}%DIFDELCMD < \eqref{eq:DistWishart}%%%
\DIFdel{.
}\DIFdelend Since we are interested in describing the information conveyed by parts of such matrix \DIFdelbegin \DIFdel{, we rely on the results presented in~\mbox{%DIFAUXCMD
\cite{lee,hsbmp}}\hspace{0pt}%DIFAUXCMD
.
In particular}\DIFdelend \DIFaddbegin \DIFadd{under the Wishart model}\DIFaddend , we assume that the distribution of each intensity channel is a 
Gamma law with probability density function
\begin{equation}
f_Z(z;\mu,L)=\frac{L^{L}z^{L-1}}{\mu^{L}\Gamma(L)} \exp\big\{-Lz/\mu\big\},\quad z>0,
\label{func_dens_uni_gamma}
\end{equation}
where $L>0$\DIFdelbegin \DIFdel{(rather than $L\geq1$ to allow for flexibility)}\DIFdelend , and
$\mu>0$ is the mean.
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Given }\DIFdelend \DIFaddbegin \DIFadd{The log-likelihood of }\DIFaddend the sample $\bm z = (z_1,\dots,z_n)$ \DIFdelbegin \DIFdel{,
the reduced log-likelihood of }\DIFdelend \DIFaddbegin \DIFadd{under }\DIFaddend this model is
\begin{equation}
\DIFdelbegin \DIFdel{\ell}\DIFdelend \DIFaddbegin \DIFadd{\mathcal L}\DIFaddend ( \DIFdelbegin %DIFDELCMD < \bm %%%
\DIFdel{z; }\DIFdelend L,\mu\DIFaddbegin \DIFadd{;}\DIFaddend \DIFaddbegin \DIFadd{z}\DIFaddend ) = n \big[L\ln (L / \mu) - \ln \Gamma(L)\big]
+L \sum_{k=1}^{n}\ln z_k -\frac{L}{\mu}\sum_{k=1}^{n} z_k.
\label{eq:LogLikelihoodGamma}
\end{equation}

We obtain \DIFdelbegin \DIFdel{$(\widehat L, \widehat \mu)$}\DIFdelend \DIFaddbegin \DIFadd{$\big(\widehat L, \widehat \mu\big)$}\DIFaddend , the maximum likelihood estimator (MLE) of $(L, \mu)$ based on $\bm z$, by maximizing~\eqref{eq:LogLikelihoodGamma} with the BFGS method\DIFdelbegin \DIFdel{implemented in the }\texttt{\DIFdel{maxLik}} %DIFAUXCMD
\DIFdel{package}\DIFdelend ~\cite{ht}.
We prefer optimization to solving $\nabla\ell=\bm 0$ for improved numerical stability.

\section{Edge Detection on a Single Data Strip}\label{sec_03}

\DIFdelbegin \DIFdel{We approach edge detection with the Gambini Algorithm~\mbox{%DIFAUXCMD
\cite{gmbf, fbgm, nhfc}}\hspace{0pt}%DIFAUXCMD
.
%DIF < %% ACF
%DIF < This technique is convenient for our subsequent fusion step, since it provides estimates of the edge location over the same ray.
It consists of the following steps:
}%DIFDELCMD < \begin{enumerate}
\begin{enumerate}%DIFAUXCMD
%DIFDELCMD < 	\item %%%
\item%DIFAUXCMD
\DIFdel{Identify the centroid of a region of interest (ROI) in an automatic, semi-automatic or manual manner.
}%DIFDELCMD < \item %%%
\item%DIFAUXCMD
\DIFdel{Cast rays from the centroid to the outside of the area.
	}%DIFDELCMD < \item %%%
\item%DIFAUXCMD
\DIFdel{Collect data on a strip, ideally of the size of a pixel, around the rays using the  Bresenham's midpoint line algorithm.
	}%DIFDELCMD < \item %%%
\item%DIFAUXCMD
\DIFdel{Compute the value functionon every point of the ray.
	}%DIFDELCMD < \item %%%
\item%DIFAUXCMD
\DIFdel{Use the GenSA method~\mbox{%DIFAUXCMD
\cite{xgsh}}\hspace{0pt}%DIFAUXCMD
, to find points of maxima in the functions of interest.
}%DIFDELCMD < \item %%%
\item%DIFAUXCMD
\DIFdel{Fuse the evidence of detected edges in the (hh), (hv) and (vv) channels.
}
\end{enumerate}%DIFAUXCMD
%DIFDELCMD < \end{enumerate}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{The Gambini algorithm estimates the point at which the properties of a sample change.
It has been used with stochastic distances~\mbox{%DIFAUXCMD
\cite{nhfc}}\hspace{0pt}%DIFAUXCMD
, and with the likelihood function~\mbox{%DIFAUXCMD
\cite{gmbf, fbgm} }\hspace{0pt}%DIFAUXCMD
for edge detection in SAR/PolSAR imagery.
It can be adapted to any suitable measure of dissimilarity between two samples.
}\DIFaddend 

The \DIFdelbegin \DIFdel{value function is the reduced log-likelihood of the inner and external samples of the strip denoted, respectively, as $\bm z_\text{I}$ and $\bm z_\text{E}$.
Each strip }\DIFdelend \DIFaddbegin \DIFadd{algorithm starts by casting rays from a point inside the candidate region, e.g., the centroid.
Data are collected around each ray to form the sample }\DIFaddend $\bm z = (z_1,z_2,\dots,z_n)$\DIFdelbegin \DIFdel{is, thus, partitioned in two disjoint samples }\DIFdelend \DIFaddbegin \DIFadd{, which is partitioned }\DIFaddend at position $j$:
$$
\bm z = (\underbrace{z_1,z_2,\dots,z_j}_{\bm z_\text{I}}, 
\underbrace{z_{j+1}, z_{j+2},\dots,z_n}_{\bm z_\text{E}}).
$$
We assume two (possibly) different models for each partition:
$\bm Z_\text{I} \sim \Gamma(\mu_\text{I},L_\text{I})$, and 
$\bm Z_\text{E} \sim \Gamma(\mu_\text{E},L_\text{E})$.
We then estimate $(\mu_\text{I},L_\text{I})$ and $(\mu_\text{E},L_\text{E})$ with $\bm z_\text{I}$ and $\bm z_\text{E}$, respectively, by maximizing~\eqref{eq:LogLikelihoodGamma}, and obtain \DIFdelbegin \DIFdel{$(\widehat{\mu}_\text{I}, \widehat{L}_\text{I})$ and $(\widehat{\mu}_\text{E}, \widehat{L}_\text{E})$}\DIFdelend \DIFaddbegin \DIFadd{$\big(\widehat{\mu}_\text{I}, \widehat{L}_\text{I}\big)$ and $\big(\widehat{\mu}_\text{E}, \widehat{L}_\text{E}\big)$}\DIFaddend .

\DIFdelbegin \DIFdel{The }\DIFdelend \DIFaddbegin \DIFadd{We then compute the }\DIFaddend total log-likelihood \DIFdelbegin \DIFdel{at point $j$ is, then,
}\DIFdelend \DIFaddbegin \DIFadd{of $\bm z_\text{I}$ and $\bm z_\text{E}$:
}\DIFaddend \begin{equation}\label{eq:TotalLogLikelihood}
\DIFdelbegin %DIFDELCMD < \begin{split}
%DIFDELCMD < %\ell(j&;\bm z_\text{I},\bm z_\text{E}) = \\
%DIFDELCMD < \ell(j&;\widehat{\mu}_I, \widehat{L}_I,\widehat{\mu}_E, \widehat{L}_E)=\\
%DIFDELCMD < &j \big[\widehat{L}_\text{I}\ln (\widehat{L}_\text{I} / \widehat{\mu}_\text{I}) - \ln \Gamma(\widehat{L}_\text{I})\big]
%DIFDELCMD < +\widehat{L}_\text{I} \sum_{k=1}^{j}\ln z_k -\frac{\widehat{L}_\text{I}}{\widehat{\mu}_\text{I}}\sum_{k=1}^{j} z_k +\\
%DIFDELCMD < &(n-j) \big[\widehat{L}_\text{E}\ln (\widehat{L}_\text{E} / \widehat{\mu}_\text{E}) - \ln \Gamma(\widehat{L}_\text{E})\big]
%DIFDELCMD < +\widehat{L}_\text{E} \sum_{k=j+1}^{n}\ln z_k -\\ &\frac{\widehat{L}_\text{E}}{\widehat{\mu}_\text{E}}\sum_{k=j+1}^{n} z_k.
%DIFDELCMD < \raisetag{2.2em}
%DIFDELCMD < \end{split}%%%
\DIFdelend \DIFaddbegin \begin{aligned}
\mathcal L\big(j&;\widehat{\mu}_I, \widehat{L}_I,\widehat{\mu}_E, \widehat{L}_E\big)= -\Bigg(
	\frac{\widehat{L}_\text{I}}{\widehat{\mu}_\text{I}}\sum_{k=1}^{j} z_k +
	\frac{\widehat{L}_\text{E}}{\widehat{\mu}_\text{E}}\sum_{k=j+1}^{n} z_k  
	\Bigg)+\mbox{}\\
&j \big[\widehat{L}_\text{I}\ln (\widehat{L}_\text{I} / \widehat{\mu}_\text{I}) - \ln \Gamma(\widehat{L}_\text{I})\big]
+\widehat{L}_\text{I} \sum_{k=1}^{j}\ln z_k + \mbox{}\\
&(n-j) \big[\widehat{L}_\text{E}\ln (\widehat{L}_\text{E} / \widehat{\mu}_\text{E}) - \ln \Gamma(\widehat{L}_\text{E})\big]
+\widehat{L}_\text{E} \sum_{k=j+1}^{n}\ln z_k .%-\\ 
\raisetag{2.2em}
\end{aligned}\DIFaddend 
\end{equation}
\DIFdelbegin \DIFdel{We then apply GenSA to find  
}\begin{displaymath}
\DIFdel{\widehat{\jmath}= \arg\max\limits_{j\in [\min_s,N-\min_s]}\ell(j;\widehat{\mu}_I, \widehat{L}_I,\widehat{\mu}_E, \widehat{L}_E),
}\end{displaymath}%DIFAUXCMD
%DIFDELCMD <  
%DIFDELCMD < %%%
\DIFdel{where $\min_s$ is a }\DIFdelend \DIFaddbegin \DIFadd{and the estimate of the edge position on the ray is the coordinate $\widehat\jmath$ which maximizes it.
}

\DIFadd{Algorithm~\ref{Algo:GambiniEdgeDetection} is the pseudocode of the basic edge detection with the Gambini Algorithm.
We found that one hundred rays is a good compromise between spatial continuity and computational load.
Also, $\min_s$ is the }\DIFaddend minimum sample size\DIFdelbegin \DIFdel{that we set to $14$.}\DIFdelend \DIFaddbegin \DIFadd{.%DIF >  that we set to $14$.
}\DIFaddend 

\DIFdelbegin \DIFdel{In this way, we obtain one estimates for the edge for each intensity channel.
Notice that this approach can be extended and/or modified to cope with any kind of data.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{We will see ways of fusing these evidences in the next section}\DIFdelend \DIFaddbegin \begin{algorithm}[hbt]
\SetAlgoLined
\KwData{$n_c$ intensity channels, interior point, number of rays}
\KwResult{$n_c$ binary images with evidences of edges}
%DIF > initialization\;
\For{each band $1\leq c\leq n_c$}{
	\For{each ray passing through the interior point}{
		$\bm z = (z_1,z_2,\dots,z_n)\leftarrow$ data collected around the ray\;
		\For{each $\min_s\leq j\leq n-\min_s$}{\nllabel{Line:InitFor}
			Partition the sample as $\bm z_{\text{I}}=(z_{\min_s},\dots,z_j)$ and 
			$\bm z_{\text{E}}=(z_{j+1},\dots,z_{n-\min_s})$\;
			Compute $\big(\widehat{\mu}_\text{I}, \widehat{L}_\text{I}\big)$ with $\bm z_{\text{I}}$, and $\big(\widehat{\mu}_\text{E}, \widehat{L}_\text{E}\big)$ with $\bm z_{\text{E}}$\;
			Compute the total log-likelihood at $j$ as $\mathcal L\big(j;\widehat{\mu}_I, \widehat{L}_I,\widehat{\mu}_E, \widehat{L}_E\big)$\;
		}
		$\widehat\jmath\leftarrow$ the value of $j$ which maximizes the total log-likelihood function\;
		\Return $(\widehat x, \widehat y)$, the coordinates of each $\widehat\jmath$\;
	}
\Return the binary image $\widehat{\bm\jmath}_c$ with $1$ at every $(\widehat x, \widehat y)$, and $0$ otherwise.
}
\caption{\DIFadd{Gambini algorithm for intensity channels}}\label{Algo:GambiniEdgeDetection}
\end{algorithm}

\DIFadd{In our implementation, we replace the exhaustive sequential search (the innermost }\textbf{\DIFadd{for}} \DIFadd{loop) by Generalized Simulated Annealing (GenSA~\mbox{%DIFAUXCMD
\cite{xgsh}}\hspace{0pt}%DIFAUXCMD
)}\DIFaddend .

%DIF > Notice that this approach can be extended and/or modified to cope with any kind of data.
%DIF > We will see ways of fusing these evidences in the next section.
\DIFaddbegin 

\DIFaddend \section{Fusion of Evidences}\label{sec_04}

\DIFdelbegin \DIFdel{Denote in the following $\widehat{\bm\jmath}_c$ the binary image with same support as the input data $c$ ($m$ lines and $n$ columns; denote $\ell=mn$), where }\DIFdelend \DIFaddbegin \DIFadd{Assume we have $n_c$ binary images $\{\widehat{\bm\jmath}_c\}_{1\leq c\leq n_c}$ in which~}\DIFaddend $1$ denotes an estimate of edge and $0$ otherwise.
\DIFdelbegin \DIFdel{We have $n_c$ of these image to fuse, and the result of the fusion will be denoted }\DIFdelend \DIFaddbegin \DIFadd{They have common size $m\times n$; denote $\ell=mn$.
These images will be fused to obtain the binary image }\DIFaddend $\bm I_F$.

%DIF > Denote in the following $\widehat{\bm\jmath}_c$ the binary image with same support as the input data $c$ ($m$ lines and $n$ columns; denote $\ell=mn$), where $1$ denotes an estimate of edge and $0$ otherwise.
%DIF > We have $n_c$ of these image to fuse, and the result of the fusion will be denoted $\bm I_F$.
\DIFaddbegin 

\DIFaddend We compare the results of six fusion techniques\DIFdelbegin \DIFdel{, namely}\DIFdelend :
simple average, 
multi-resolution discrete wavelet transform (MR-DWT),
principal components analysis (PCA), 
ROC statistics,
multi-resolution stationary wavelet transform (MR-SWT), and
multi-resolution singular value decomposition (MR-SVD).

%The estimated evidence image and the fusion image are defined to perform the fusion techniques. The first can be defined as $\widehat\jmath_c(x,y)$, where $x$ and $y$, indicate the range of pixels in an image equal in size to the data image chosen for analysis. The image is binary, where the value one is put on the pixel estimated as edge evidence by the MLE method, and zero on the other pixels, for each channel. The second called $\text{I}_F(x,y)$ is the result of the fusion method. 

%Refs.~\cite{bmf_2019,n_r,mit,gs,fawcett} provide details about the three first.
%We describe the two latter below.

\subsection{Simple Average}
The simple average fusion method proposes the arithmetic mean of the edge evidence in each of the $n_c$ channels:
$\bm I_F(x,y)=(n_c)^{-1}\sum_{c=1}^{n_c} \widehat{\bm\jmath}_c(x,y)$\DIFaddbegin \DIFadd{,
where $1\leq x\leq m$ indexes the rows, and $1\leq y\leq n$ the columns of the image}\DIFaddend .
%where $\widehat\jmath_c$ denotes the estimate obtained in channel $c$.

\subsection{Multi-Resolution Discrete Wavelet -- MR-DWT} 
This section is based on~\cite{n_r}.
%We apply DWT filters separately in the vertical and horizontal directions of each image $\bm{\widehat\jmath}_c$, then down-sampled by a factor of two. 
%In this way, each image is filtered by the low pass filter $\text{L}$ in the vertical direction and the high pass filter $\text{H}$ in the horizontal direction, then down-sampled to create the matrices coefficients  $\bm{\widehat\jmath}_{c\text{L}}$ and $\bm{\widehat\jmath}_{c\text{H}}$.
We apply DWT filters on each binary image $\bm{\widehat\jmath}_c$: a low-pass filter $\bm L$ in the vertical direction, and a high-pass filter $\bm H$ in the horizontal direction, then both are down-sampled to create the coefficient matrices $\bm{\widehat\jmath}_{c\text{L}}$ and $\bm{\widehat\jmath}_{c\text{H}}$.
These operations are repeated on the coefficient matrices, leading to $\bm{\widehat\jmath}_{c\text{LL}}$, $\bm{\widehat\jmath}_{c\text{LH}}$, $\bm{\widehat\jmath}_{c\text{HL}}$, and $\bm{\widehat\jmath}_{c\text{HH}}$.

%%% ACF Detalhar as operações usando a notação acima: a média é pixel-a-pixel? quais bandas são promediadas?
%%% AAB A média é pixel a pixel. Todas as bandas são usadas na média. Vou tentar deixar claro no texto. Creio que respondi no item 2 abaixo.
%%% AAB Eu entendo que investigar outros tipo de ponderação (suprimir canais, por exemplo) pode ser realizado. Ainda não consegui fazer esses testes.
%%% AAB O nivel de resolução que uso é 1, esse é outro ponto de investigação, seria interessante aumentar esse nível e ver o que acontece na fusão. Tb não consegui realizar esses teste. Inseri no item 1) abaixo a info sobre o nível de resolução.
The DWT fusion method has the following steps:
\begin{enumerate}
\item Calculate the DWT decomposition $\bm{\widehat\jmath}_{c\text{LL}}$, $\bm{\widehat\jmath}_{c\text{LH}}$, $\bm{\widehat\jmath}_{c\text{HL}}$, and $\bm{\widehat\jmath}_{c\text{HH}}$, for each channel.
\item Compute $\bm{\bar\jmath}_{c\text{HH}}$, the pixel-wise mean of all $\bm{\widehat\jmath}_{c\text{HH}}$ decompositions.
\item Find the pixel-wise maximum of $\bm{\widehat\jmath}_{c\text{LL}}$, $\bm{\widehat\jmath}_{c\text{LH}}$, $\bm{\widehat\jmath}_{c\text{HL}}$: $\bm{\bar\jmath}_{c\text{LL}}$, $\bm{\bar\jmath}_{c\text{LH}}$, and $\bm{\bar\jmath}_{c\text{HL}}$.
%%% AAB(03/03/2020) tenho uma dúvida, o máximo(pixel a pixel) deve ser calculada entre os operadores da decomposiçcao em cada canal. Não seria bom deixar claro como no item anterior?
\item The result of the fusion $I_F$ is the inverse DWT \DIFdelbegin \DIFdel{transformation }\DIFdelend \DIFaddbegin \DIFadd{transform }\DIFaddend of the coefficient matrices $\bm{\bar\jmath}_{c\text{HH}}$, $\bm{\bar\jmath}_{c\text{LL}}$, $\bm{\bar\jmath}_{c\text{LH}}$, and $\bm{\bar\jmath}_{c\text{HL}}$.
\end{enumerate}
%%% ACF Aqui dizer que é a Inverse DWT do que
\subsection{Principal Component Analysis -- PCA}

%%% ACF Revisar e corrigir a notação; usar notação matemática sempre que necessário
This section is based on~\cite{n_r,mit}.
The method is comprised of the following steps:
\begin{enumerate}
\item Stack the binary images $\bm{\widehat\jmath}_c$ in column vectors to obtain the matrix $\bm X_{\ell\times n_c}$.
%\item Calculate the average of the elements of these columns, generating a vector of dimension of $1\times nc$.
%%% ACF A matriz de covariância é invariante a traslações. Precisa deste passo?
%\item subtract the average of each column from $\text Y$, resulting in a matrix of the same dimension of $\text X$; 
\item Calculate the covariance matrix $\bm C_{n_c\times n_c}$ of $\bm X_{\ell\times n_c}$.
\item Compute the matrices of eigenvalues ($\bm\Lambda$) and eigenvectors ($\bm V$) of the covariance matrix, sorted in decreasing order by the eigenvalues. %The matrices generated by the eigenvalues, on the principal diagonal, and the eigenvectors placed in columns;
%%% ACF O que é V_c?
\item Compute the \DIFdelbegin \DIFdel{components $\bm P_c=(\sum_{m=1}^{n_c} \bm V_c(m))^{-1}{\bm V_c}$, where $\bm V_c$ }\DIFdelend \DIFaddbegin \DIFadd{vector $\bm P=(P(1),\dots,P(n_c))=(\sum_{c=1}^{n_c} V(c))^{-1}{\bm V}$, where $\bm V$ }\DIFaddend is eigenvector associated with the highest eigenvalue of \DIFdelbegin \DIFdel{$\bm X$}\DIFdelend \DIFaddbegin \DIFadd{$\bm C_{n_c\times n_c}$}\DIFaddend ; notice that \DIFdelbegin \DIFdel{$\sum_{c=1}^{n_c}\bm P_c=1$}\DIFdelend \DIFaddbegin \DIFadd{$\sum_{c=1}^{n_c} P(c)=1$}\DIFaddend .
\item Fuse \DIFdelbegin \DIFdel{$\bm I_F(x,y)=\sum_{c=1}^{n_c}\bm P_c\bm{\widehat\jmath}_c(x,y)$}\DIFdelend \DIFaddbegin \DIFadd{$\bm I_F(x,y)=\sum_{c=1}^{n_c} P(c)\bm{\widehat\jmath}_c(x,y)$}\DIFaddend .
\end{enumerate}

\subsection{ROC Statistics}
The ROC method was proposed and described on~\DIFdelbegin \DIFdel{\mbox{%DIFAUXCMD
\cite{gs,fawcett}}\hspace{0pt}%DIFAUXCMD
}\DIFdelend \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\cite{gs}}\hspace{0pt}%DIFAUXCMD
}\DIFaddend :
\begin{enumerate}
%\item the evidence of edges in each channels $\bm{\widehat\jmath}_c$, with $c=1,\dots,nc$ in a binary way;
%%% AAB(03/03/2020) Aqui fico em dúvida se coloco "matrices" ou  "binary images".  
\item Add the binary images $\bm{\widehat\jmath}_c$ to produce the frequency matrix ($\bm V$).
\item Use thresholds ranging from $t=1,\dots,n_c$ on $\bm V$ to generate matrices $\bm M_t$.
\item Compare each $\bm M_t$ with all $\bm{\widehat\jmath}_c$, find the confusion matrix to generate the ROC curve. 
The optimal threshold corresponds to the point of the ROC curve closest (in the sense of the Euclidean distance) to the diagnostic line.
\item The fusion $\bm I_F$ is the matrix $\bm M_t$ which corresponds to the optimal threshold.
\end{enumerate}

\subsection{Multi-Resolution Stationary Wavelet Transform -- MR-SWT}  
This section is based on~\cite{n_r, jjly}. The difference between MR-DWT and MR-SWT method is the replacement of the 
\DIFdelbegin \DIFdel{method discrete wavelet transform }\DIFdelend \DIFaddbegin \DIFadd{Discrete Wavelet Transform }\DIFaddend (DWT) by the
\DIFdelbegin \DIFdel{method stationary wavelet transform }\DIFdelend \DIFaddbegin \DIFadd{Stationary Wavelet Transform }\DIFaddend SWT. 
%%% ACF Esclarecer quais são estes filtros

\subsection{Multi-Resolution Singular Value Decomposition -- MR-SVD}

MR-SVD Fusion~\cite{naidu} works similarly to MR-DWT. 
\DIFdelbegin \DIFdel{The difference consists in changing the DWT filters by the SVD filters. 
The }\DIFdelend %DIF > The difference consists in changing the DWT filters by the SVD filters. 
\DIFaddbegin \DIFadd{The }\DIFaddend MR-SVD fusion method can be summarized as follows:
\begin{enumerate}
%\item Organize the binary image $\bm{\widehat\jmath}_c$ in matrices $\text{X}_\ell$ with dimension $4\times\frac{\text{M}}{2}\frac{\text{N}}{2}$ according to~\cite{naidu}, where M is the number of rows and N is the number of columns in $\bm{\widehat\jmath}_c$, and $\ell$ is the level resolution to set. In this work is used one resolution level;
\item Organize the binary image $\bm{\widehat\jmath}_c$ as non-overlapping $2\times 2$ blocks, and arrange each block as a $4\times 1$ vector by stacking columns to form the data matrix $\bm X_1$ with dimension ${4\times{\ell}/{4}}$.
%, where M is the number of rows and N is the number of columns in $\bm{\widehat\jmath}_c$, 
%and $\ell$ is the level resolution to set. In this work is used one resolution level.
%%% ACF Repare que não usou M nem N
\item Find the SVD decomposition of $\bm X_1=\bm U_1 \bm S_1 \bm V_1^T$, where $\bm U_1$ \DIFdelbegin \DIFdel{and $\bm V_1$ are  unitary and they have dimensions }\DIFdelend \DIFaddbegin \DIFadd{is a }\DIFaddend ${4\times 4}$ \DIFdelbegin \DIFdel{e ${\ell}/{4}\times{\ell}/{4}$ respectively. The diagonal entries $S_{ii}$ of }\DIFdelend \DIFaddbegin \DIFadd{unitary matrix, }\DIFaddend $\bm S_1$ \DIFdelbegin \DIFdel{are known as the singular values of $\bm X_1$ and it have dimension }\DIFdelend \DIFaddbegin \DIFadd{is a }\DIFaddend $4\times{\ell}/{4}$ \DIFaddbegin \DIFadd{rectangular diagonal matrix known as singular values matrix, and $\bm V_1$ is an ${\ell}/{4}\times{\ell}/{4}$~unitary matrix}\DIFaddend . The singular values are \DIFdelbegin \DIFdel{sorted in descending, and they are putting in the diagonal principal of the matrix, other entries must be zeros}\DIFdelend \DIFaddbegin \DIFadd{ordered in a decreasing order}\DIFaddend .
% and calculate $\bm T_1=\bm X_1 \bm X_1^T=\bm U_1 \bm S_1^2 \bm U_1^T\Sigma \bm V^T$, where $s(1)\geq s(2) \geq s(3) \geq s(4)$ comprise the singular value matrix $\bm S_1$, 
%%% ACF Não definiu nem usou s(1), s(2) etc
%%% AAB Os s(1), s(2), s(3) e s(4) são usados para gerar a matriz $S$
% and $\bm U_1$ is unitary.
\item 
Transform the lines of $\widehat{\bm X}_1=\bm U_1^T\bm X_1=\bm S_1 \bm V_1^T$ into new matrices with dimensions ${m}/{2}\times{n}/{2}$: $\{\bm\Phi_1, \bm\Psi_{1\text{V}}, \bm\Psi_{1\text{H}}, \bm\Psi_{1\text{D}}\}$. 
%\item Repeat the procedure on $\Phi_r$ $R$ times. Where $r=1,\dots,\text{R}$ and, R is lowest resolution index. 
\item Repeat the procedure (1) on $\bm\Phi_r$ by $r=2$ up to the lowest resolution level $R$. 
\item The MR-SVD decomposition in each channel is
\begin{equation}\nonumber
\widehat{\bm X}_c\rightarrow \left\{\bm \Phi_\text{R}^c,\{\bm\Psi_{r\text{V}}^c,\bm\Psi_{r\text{H}}^c,\bm\Psi_{r\text{D}}^c \}_{r=1}^\text{R},\{\bm U_r^c	\}_{r=1}^\text{R} \right\}.
\end{equation}
%\item Once the SVD is applied to level $\ell$ the fusion process is executed as follow: In the operators $\Psi_\ell^\text{V}$, $\Psi_\ell^\text{H}$ and $\Psi_\ell^\text{D}$, the maximum is found among all channel, pixel by pixel, resulting in new operators $\bar{\Psi}_\ell^\text{V}$, $\bar{\Psi}_\ell^\text{H}$ and $\bar{\Psi}_\ell^\text{D}$. 
%The operators $\Phi_L$, and $\text{U}_\ell$ are averaged over all the channels, pixel by pixel.
\item Once the decomposition is applied to all channels, 
compute the average of $\bm\Phi_R^c$ ($\bm\Phi_\text{R}^f$) in the lowest resolution level, and the average 
of $\bm U_r^c$ ($\bm U_\text{r}^f$), for each $r$, where $f$ denotes the fusion among channels. 
%\item Find the pixel-wise maxima of $\bm\Psi_r^\text{V}$, $\bm\Psi_r^\text{H}$ and $\bm\Psi_r^\text{D}$ :$ \prescript{}{2}{\mathbf{\bm\Psi}}^{V}_{r}$ $\overline{\bm\Psi}_r^\text{V}$, $\overline{\bm\Psi}_r^\text{H}$ and $\overline{\bm\Psi}_r^\text{D}$.
\item Find the pixel-wise maxima of $\bm\Psi_{r\text{V}}^c$, $\bm\Psi_{r\text{H}}^c$ and $\bm\Psi_{r\text{D}}^c$: $ \bm\Psi_{rV}^f$ $\bm\Psi_{r\text{V}}^f$, $\bm\Psi_{r\text{H}}^f$ and $\bm\Psi_{r\text{D}}^f$.
\item The fusion $\bm I_F$ is the SVD transformation for each level $r=\text{R},\dots,1$,  
\begin{equation}\nonumber
\bm I_F\leftarrow \left\{\bm \Phi_\text{R}^f,\{\bm\Psi_{r\text{V}}^f,\bm\Psi_{r\text{H}}^f,\bm\Psi_{r\text{D}}^f \}_{r=\text{R}}^1,\{\bm U_r^f\}_{r=\text{R}}^1 \right\}.
\end{equation}
\end{enumerate}

\section{Results}\label{sec_05}

\subsection{\DIFdelbegin \DIFdel{PolSAR image}\DIFdelend \DIFaddbegin \DIFadd{Flevoland images}\DIFaddend }

\DIFdelbegin \DIFdel{We used }\DIFdelend \DIFaddbegin \DIFadd{Fig.~\ref{roi_gt}}\subref{flevoland_radial_4look} \DIFadd{shows }\DIFaddend a $750\times 1024$ pixels AIRSAR PolSAR image of Flevoland, L-band, \DIFdelbegin \DIFdel{for the tests. 
Fig.~\ref{flevoland_radial_4look} shows the ROI, }\DIFdelend with the radial lines where edges are detected. 
Fig.~\DIFdelbegin \DIFdel{\ref{gt_flevoland} }\DIFdelend \DIFaddbegin \DIFadd{\ref{roi_gt}}\subref{gt_flevoland} \DIFaddend shows the ground reference in red.  

%DIF < \begin{figure}[hbt]
%DIF < \centering
%DIF < 	\includegraphics[width=0.50\linewidth]{flevoland_radial_4_look_black}
%DIF < 	\caption{Flevoland image in Pauli decomposition, with Region of Interest (ROI) and rays.}
%DIF < \label{flevoland_radial_4look}
%DIF < \end{figure}
   \begin{figure}[hbt]
   \centering
     \DIFdelbeginFL %DIFDELCMD < \subfloat[Image, Region of Interest (ROI), and rays. \label{flevoland_radial_4look}]{%
%DIFDELCMD < %       \includegraphics[viewport= 0 50 500 550, clip=true, width=0.23\textwidth]{flevoland_radial_4_look_black_crop}}      
%DIFDELCMD <        \includegraphics[width=0.229\textwidth]{flevoland_radial_4_look_black_crop}}
%DIFDELCMD <      %%%
\DIFdelendFL \DIFaddbeginFL \subfloat[Image and rays. \label{flevoland_radial_4look}]{%  
       \includegraphics[width=0.229\textwidth]{flevoland_radial_4_look_black_crop}}
     \DIFaddendFL \subfloat[Ground reference\label{gt_flevoland}]{%
       \includegraphics[width=0.216\textwidth]{gt_flevoland_crop}
     }
    \caption{Flevoland image in Pauli decomposition, \DIFdelbeginFL \DIFdelFL{region of interest, }\DIFdelendFL and ground reference}
    \label{roi_gt}
\end{figure}

%DIF < The estimates from equation~\eqref{eq:LogLikelihoodGamma} is used in equation~\eqref{eq:TotalLogLikelihood} generating an oscillation at the end of each radial line, depending on the radial considered. In order to get around this problem, in this PolSAR image, 14 pixels on each side of radial lines were not considered. The number of pixel were determined empirically.
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend Figs.~\ref{evidencias_hh_hv_vv}\subref{evidencias_hh_hv_vv:a}, \ref{evidencias_hh_hv_vv}\subref{evidencias_hh_hv_vv:b}, and~\ref{evidencias_hh_hv_vv}\subref{evidencias_hh_hv_vv:c} show, respectively, the edge evidences in the $\text{hh}$, $\text{hv}$ and $\text{vv}$ channels as obtained by MLE.

It is worth noting that GenSA has accurately identified the maximum value of \DIFdelbegin \DIFdel{$\ell$}\DIFdelend \DIFaddbegin \DIFadd{$\mathcal L$ (Eq.}\DIFaddend ~\eqref{eq:TotalLogLikelihood}\DIFaddbegin \DIFadd{)}\DIFaddend , even in the presence of multiple local maxima. 
A visual assessment leads to conclude that the best results are provided by $\text{hv}$, although with a few points far from the actual edge.

   \DIFdelbegin %DIFDELCMD < \begin{figure*}[hbt]
%DIFDELCMD < 	%%%
\DIFdelendFL \DIFaddbeginFL \begin{figure}[hbt]
	\DIFaddendFL \centering
     \DIFdelbeginFL %DIFDELCMD < \subfloat[Evidences in channel $\text{hh}$ \label{evidencias_hh_hv_vv:a}]{%
%DIFDELCMD <        \includegraphics[width=0.32\linewidth]{flevoland_hh_evid_param_L_mu_14_pixel_crop}
%DIFDELCMD <      }
%DIFDELCMD <      \subfloat[Evidences in channel $\text{hv}$ \label{evidencias_hh_hv_vv:b}]{%
%DIFDELCMD <        \includegraphics[width=0.32\linewidth]{flevoland_hv_evid_param_L_mu_14_pixel_crop}
%DIFDELCMD <      }
%DIFDELCMD <      \subfloat[Evidences in channel $\text{vv}$ \label{evidencias_hh_hv_vv:c}]{%
%DIFDELCMD <        \includegraphics[width=0.32\linewidth]{flevoland_vv_evid_param_L_mu_14_pixel_crop}
%DIFDELCMD <      }
%DIFDELCMD <      %%%
\DIFdelendFL \DIFaddbeginFL \subfloat[Channel $\text{hh}$ \label{evidencias_hh_hv_vv:a}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_hh_evid_param_L_mu_14_pixel_crop}
     }
     \subfloat[Channel $\text{hv}$ \label{evidencias_hh_hv_vv:b}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_hv_evid_param_L_mu_14_pixel_crop}
     }
     \subfloat[Channel $\text{vv}$ \label{evidencias_hh_hv_vv:c}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_vv_evid_param_L_mu_14_pixel_crop}
     }
     \DIFaddendFL \caption{Edges evidences from the three intensity channels}
     \label{evidencias_hh_hv_vv} 
   \DIFdelbeginFL %DIFDELCMD < \end{figure*}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \end{figure}
\DIFaddend 

Figs.~\ref{fusion_met}\subref{fusion_met:a}, 
\DIFaddbegin \DIFadd{\ref{fusion_met}}\DIFaddend \subref{fusion_met:b}, 
\DIFaddbegin \DIFadd{\ref{fusion_met}}\DIFaddend \subref{fusion_met:c}, 
\DIFaddbegin \DIFadd{\ref{fusion_met}}\DIFaddend \subref{fusion_met:d}, 
\DIFaddbegin \DIFadd{\ref{fusion_met}}\DIFaddend \subref{fusion_met:e}, 
and~\DIFaddbegin \DIFadd{\ref{fusion_met}}\DIFaddend \subref{fusion_met:f} show the results of fusing these evidences. 

%Thus, one can see that the time for the PCA method is 2.19 times longer than the simple average.  

\DIFdelbegin \DIFdel{The simple }\DIFdelend \DIFaddbegin \DIFadd{Simple }\DIFaddend average and PCA produce similar results.
MR-SVD produces considerably less outliers than the other methods\DIFdelbegin \DIFdel{, at the cost of longer processing time}\DIFdelend .
ROC produces accurate edges, with few outliers, but sparsely. 
%One way to get around this problem would be to increase the number of channels considered using other PDF.
Both wavelet-based methods (DWT and SWT) produce too dense edges and many outliers.

%The post-processing is an option to be used in all the fusion methods. 
%An idea can be found in Ref.~\cite{fbgm}. 

\DIFdelbegin %DIFDELCMD < \begin{figure*}[hbt]
%DIFDELCMD < 	%%%
\DIFdelendFL \DIFaddbeginFL \begin{figure}[hbt]
	\DIFaddendFL \centering
     \subfloat[Average fusion\label{fusion_met:a}]{%
       %\includegraphics[width=0.2\textwidth]{example-image-a}
       \includegraphics[width=0.32\linewidth]{flevoland_fus_media_param_L_mu_14_pixel_crop}
     }
     \subfloat[DWT fusion\label{fusion_met:b}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_fus_dwt_param_L_mu_14_pixel_crop}
     }
     \subfloat[PCA fusion \label{fusion_met:c}]{%
       %\includegraphics[width=0.2\textwidth]{example-image-a}
       \includegraphics[width=0.32\linewidth]{flevoland_fus_pca_param_L_mu_14_pixel_crop}       
     }\\
     \subfloat[ROC fusion\label{fusion_met:d}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_fus_roc_param_L_mu_14_pixel_crop}
     }
     \subfloat[MR-SWT fusion\label{fusion_met:e}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_fus_swt_param_L_mu_14_pixel_crop}
     }
     \subfloat[MR-SVD fusion\label{fusion_met:f}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_fus_svd_param_L_mu_14_pixel_crop}
     }
     \caption{Results of applying the six fusion methods}
     \label{fusion_met}
\DIFdelbeginFL %DIFDELCMD < \end{figure*}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \end{figure}
\DIFaddend 

\DIFaddbegin \DIFadd{Fig.~\ref{roi_gt_2} shows another region in the Flevoland image.
In this case, it is a bright target surrounded by darker fields.
Fig.~\ref{evidencias_flev_hh_hv_vv} shows the edges detected in each intensity channel and, again, the hv data are the one which produce the most accurate results.
}

\begin{figure}[hbt]
	\centering
	\subfloat[Image and rays. \label{flevoland_radial_25}]{%  
		\includegraphics[width=.48\linewidth]{flevoland_r3_radial_crop}}
	\subfloat[Ground reference\label{gt_flevoland_r3_crop}]{%
		\includegraphics[width=.48\linewidth]{gt_flevoland_r3_crop}
	}
	\caption{\DIFaddFL{Flevoland image in Pauli decomposition, and ground reference}}
	\label{roi_gt_2}
\end{figure}

%DIF > % Teste com a região III Flevoland
%DIF > %%  25 radials lenght 120 - com folga 25
\begin{figure}[hbt]
	\centering
	\subfloat[Channel $\text{hh}$ \label{evidencias_flev_hh_hv_vv:a}]{%
		\includegraphics[width=0.32\linewidth]{evid_real_flev_hh_param_L_mu_25_pixel_r3_crop}
	}
	\subfloat[Channel $\text{hv}$ \label{evidencias_flev_hh_hv_vv:b}]{%
		\includegraphics[width=0.32\linewidth]{evid_real_flev_hv_param_L_mu_25_pixel_r3_crop}
	}
	\subfloat[Channel $\text{vv}$ \label{evidencias_flev_hh_hv_vv:c}]{%
		\includegraphics[width=0.32\linewidth]{evid_real_flev_vv_param_L_mu_25_pixel_r3_crop}
	}
	\caption{\DIFaddFL{Edges evidences from the three intensity channels, Flevoland image}}
	\label{evidencias_flev_hh_hv_vv} 
\end{figure}

\DIFadd{Fig.~\ref{fusion_flev_met} shows the two best fusion results: PCA and MR-SWD.
Notice that the latter (Fig.~\ref{fusion_flev_met}}\subref{fusion_flev_met:f}\DIFadd{) eliminates the wrong detection close to the center of the area, and has fewer wrongly detected points outside the region of interest.
}

\begin{figure}[hbt]
	\centering
%DIF > 	\subfloat[Average fusion\label{fusion_flev_met:a}]{%
%DIF > 		%\includegraphics[width=0.2\textwidth]{example-image-a}
%DIF > 		\includegraphics[width=0.32\linewidth]{flev_r3_fus_media_param_L_mu_25_pixel_crop}
%DIF > 	}
%DIF > 	\subfloat[DWT fusion\label{fusion_flev_met:b}]{%
%DIF > 		\includegraphics[width=0.32\linewidth]{flev_r3_fus_dwt_param_L_mu_25_pixel_crop}
%DIF > 	}
	\subfloat[PCA fusion \label{fusion_flev_met:c}]{%
		%\includegraphics[width=0.2\textwidth]{example-image-a}
		\includegraphics[width=0.48\linewidth]{flev_r3_fus_pca_param_L_mu_25_pixel_crop}       
	}
%DIF > 	\subfloat[ROC fusion\label{fusion_flev_met:d}]{%
%DIF > 		\includegraphics[width=0.32\linewidth]{flev_r3_fus_roc_param_L_mu_25_pixel_crop}
%DIF > 	}
%DIF > 	\subfloat[MR-SWT fusion\label{fusion_flev_met:e}]{%
%DIF > 		\includegraphics[width=0.3\linewidth]{flev_r3_fus_swt_param_L_mu_25_pixel_crop}
%DIF > 	}
	\subfloat[MR-SVD fusion\label{fusion_flev_met:f}]{%
		\includegraphics[width=0.48\linewidth]{flev_r3_fus_svd_param_L_mu_25_pixel_crop}
	}
	\caption{\DIFaddFL{Two best fusion results in the Flevoland image}}
	\label{fusion_flev_met}
\end{figure}


\subsection{\DIFadd{San Francisco Image}}

\DIFadd{Fig.~\ref{roi_gt_SF} shows an area of an L-band AIRSAR image over San Francisco.
The distinctive areas are urban, sea, and vegetation.
The aim is finding the edge between the former and the other two.
}

\begin{figure}[hbt]
	\centering
	\subfloat[Image and rays. \label{san_francisco_radial_25}]{%  
		\includegraphics[width=0.48\linewidth]{san_francisco_radial_25_crop}}\DIFaddFL{\  
	}\subfloat[Ground reference\label{gt_san_francisco}]{%
		\includegraphics[width=0.48\linewidth]{gt_san_fran_r1_crop}
	}
	\caption{\DIFaddFL{San Francisco image in Pauli decomposition, and ground reference}}
	\label{roi_gt_SF}
\end{figure}

\DIFadd{Fig.~\ref{evidencias_sf_hh_hv_vv} shows the evidences of edges found in each of the three intensity channels.
A visual inspection suggests that the hh channel is the one that produces the best estimation.
}

\begin{figure}[hbt]
	\centering
	\subfloat[Channel $\text{hh}$ \label{evidencias_sf_hh_hv_vv:a}]{%
		\includegraphics[width=0.32\linewidth]{evid_real_sf_1_param_L_mu_25_pixel_r1_crop}
	}
	\subfloat[Channel $\text{hv}$ \label{evidencias_sf_hh_hv_vv:b}]{%
		\includegraphics[width=0.32\linewidth]{evid_real_sf_2_param_L_mu_25_pixel_r1_crop}
	}
	\subfloat[Channel $\text{vv}$ \label{evidencias_sf_hh_hv_vv:c}]{%
		\includegraphics[width=0.333\linewidth]{evid_real_sf_3_param_L_mu_25_pixel_r1_crop}
	}
	\caption{\DIFaddFL{Edges evidences from the three intensity channels to San Francisco}}
	\label{evidencias_sf_hh_hv_vv} 
\end{figure}

\DIFadd{Fig.~\ref{fusion_sf_met} shows the two best fusion results: PCA and MR-SWD.
Again, the latter is more resistant to outliers, both inside and outside the region of interest.
}

\begin{figure}[hbt]
	\centering
%DIF > 	\subfloat[Average fusion\label{fusion_sf_met:a}]{%
%DIF > 		%\includegraphics[width=0.2\textwidth]{example-image-a}
%DIF > 		\includegraphics[width=0.32\linewidth]{sf_fus_media_param_L_mu_25_pixel_crop}
%DIF > 	}
%DIF > 	\subfloat[DWT fusion\label{fusion_sf_met:b}]{%
%DIF > 		\includegraphics[width=0.32\linewidth]{sf_fus_dwt_param_L_mu_25_pixel_crop}
%DIF > 	}
	\subfloat[PCA fusion \label{fusion_sf_met:c}]{%
		%\includegraphics[width=0.2\textwidth]{example-image-a}
		\includegraphics[width=0.48\linewidth]{sf_fus_pca_param_L_mu_25_pixel_crop}       
	}
%DIF > 	\subfloat[ROC fusion\label{fusion_sf_met:d}]{%
%DIF > 		\includegraphics[width=0.32\linewidth]{sf_fus_roc_param_L_mu_25_pixel_crop}
%DIF > 	}
%DIF > 	\subfloat[MR-SWT fusion\label{fusion_sf_met:e}]{%
%DIF > 		\includegraphics[width=0.32\linewidth]{sf_fus_swt_param_L_mu_25_pixel_crop}
%DIF > 	}
	\subfloat[MR-SVD fusion\label{fusion_sf_met:f}]{%
		\includegraphics[width=0.48\linewidth]{sf_fus_svd_param_L_mu_25_pixel_crop}
	}
	\caption{\DIFaddFL{Two best fusion results in the San Francisco image}}
	\label{fusion_sf_met}
\end{figure}

\subsection{\DIFadd{Error analysis}}

\DIFaddend Figure~\ref{probability_edge_detc} shows the error of $\widehat\jmath$ in finding the true edge \DIFaddbegin \DIFadd{shown in Fig.~\ref{roi_gt}}\subref{gt_flevoland}\DIFaddend , as measured on $100$ radial lines: the minimum Euclidean distance among the ground truth pixel and the several pixels detected in the fusion methods.
We use relative frequencies to estimate the probability of having an error smaller than a number of pixels. 
Denoting $H(k)$ the number of \DIFdelbegin \DIFdel{replications }\DIFdelend \DIFaddbegin \DIFadd{lines }\DIFaddend for which the error is less than $k$ pixels, an estimate of this probability is $f(k)={H(k)}/{n_r}$, where $n_r$ is \DIFdelbegin \DIFdel{the radial number }\DIFdelend \DIFaddbegin \DIFadd{number of radii}\DIFaddend . 
In our analysis, $k$ varies between $1$ and $10$\DIFaddbegin \DIFadd{, and $n_r=100$}\DIFaddend . 
The algorithm is described in Ref.~\cite{fbgm}.

\begin{figure}[hbt]
	\centering
	\includegraphics[width=.8\linewidth]{metricas_6_fusao_flevoland}
	\caption{Probability of detecting \DIFdelbeginFL \DIFdelFL{in }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{the edge by the }\DIFaddendFL fusion methods \DIFaddbeginFL \DIFaddFL{in Fig}\DIFaddendFL .\DIFaddbeginFL \DIFaddFL{~\ref{roi_gt}.}\DIFaddendFL }
	\label{probability_edge_detc}
\end{figure}

\DIFaddbegin \DIFadd{We obtained similar results on the images shown in Figs.~\ref{roi_gt_2} and~\ref{roi_gt_SF}, which we omit for brevity.
}

\DIFaddend \subsection{Implementation Details}

The system presented here was executed on a Intel\copyright\ Core i7-9750HQ CPU \SI{2.6}{\giga\hertz} \SI{16}{\giga\byte} RAM computer.  
The method for detecting edge evidence MLE was implemented in the R language.
The fusion methods were implemented in Matlab. 

Table~\ref{metrica_de_tempo} shows the running times (absolute and relative to the fastest method).

\begin{table}[hbt]
	\centering
	\caption{Processing times (fusion method).}\label{metrica_de_tempo}
	\begin{tabular}{@{}lrrrrrr@{}} \toprule
		Method       & Aver\DIFaddbeginFL \DIFaddFL{.   }\DIFaddendFL &   PCA      &  MR-DWT  & MR-SWT &  ROC  &  MR-SVD \\ \midrule
		Time (s)      & 0.01      & 0.02       &  0.08 & 0.18      &  0.40       & 1.11  \\
		Rel. time     & 1.00      & 2.19       &  9.25 & 21.05     &  46.59      & 129.57  \\ \bottomrule
	\end{tabular}
\end{table}

\section{Conclusion}\label{sec_06}

We found evidence of edges using the maximum likelihood method under the Wishart model for PolSAR data. 
The evidence was found in each of the three intensity channels of \DIFdelbegin \DIFdel{an }\DIFdelend AIRSAR L-band \DIFdelbegin \DIFdel{image over Flevoland }\DIFdelend \DIFaddbegin \DIFadd{images over Flevoland and San Francisco}\DIFaddend .

\DIFdelbegin \DIFdel{The }\DIFdelend \DIFaddbegin \DIFadd{Over the agricultural fields of Flevoland, the }\DIFaddend best edge evidence was observed on the hv channel. 
\DIFdelbegin \DIFdel{We assessed the result by checking the closeness of the fused points to the actual edge, by the presence of outliers, and by the blurring effect}\DIFdelend \DIFaddbegin \DIFadd{The vv channel provided the best estimates of the edges between the urban and both sea and vegetation areas of San Francisco.
Such diversity of information content enhances the need of fusing the edge evidences}\DIFaddend .

We applied simple average, MR-DWT, PCA, ROC, MR-SWT, and MR-SVD fusion methods to aggregate the evidence obtained in the three channels.
The best \DIFdelbegin \DIFdel{result was produced by }\DIFdelend \DIFaddbegin \DIFadd{results were produced by PCA and by }\DIFaddend the Multi-Resolution Stationary Wavelet Transform (MR-SWT)\DIFdelbegin \DIFdel{with a moderate cost of the }\DIFdelend \DIFaddbegin \DIFadd{.
Such enhancement comes at additional computational cost in terms of }\DIFaddend processing time.
\DIFaddbegin 

\DIFadd{We quantitatively assessed the result by checking the closeness of the fused points to the actual edge, and by the presence of outliers.
}


\DIFaddend %We assessed the results by checking the closeness of the fused points to the actual edge, by the presence of outliers, and by the blurring effect.

We highlight two avenues for future improvement of the fusion:
\begin{enumerate}
	\item increasing the number of evidences.
	This is possible, since fully polarimetric data \DIFdelbegin \DIFdel{is }\DIFdelend \DIFaddbegin \DIFadd{are }\DIFaddend richer than mere intensity channels; and
	\item post-processing of both partial evidences and fusion.
\end{enumerate}

%The aims to show the feasibility of a procedure for edge detection in PolSAR images using the fusion methods was reach. 
\bibliographystyle{IEEEtran}
\bibliography{RefsTengars2020}
\end{document}

